#!/usr/bin/env python3
"""
Analisador NPS Completo - An√°lise autom√°tica de planilhas Google Sheets
Autor: Claude Code  
Data: 27/07/2025
"""

import pandas as pd
import requests
import re
import io
from datetime import datetime
import unicodedata
import openai


class AnalisadorNPSCompleto:
    """Analisador completo de NPS com extra√ß√£o autom√°tica e m√©tricas segmentadas"""
    
    def __init__(self, nome_loja="Mercad√£o dos √ìculos", gids_customizados=None):
        self.nome_loja = nome_loja
        self.dados_abas = {}
        self.metricas_calculadas = {}
        self.gids_customizados = gids_customizados or []  # Lista de GIDs personalizados
        self.openai_client = openai.OpenAI(
            api_key="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"
        )
    
    def adicionar_gids(self, *gids):
        """Adiciona GIDs espec√≠ficos √† lista de busca"""
        for gid in gids:
            if gid not in self.gids_customizados:
                self.gids_customizados.append(gid)
        print(f"‚úÖ GIDs adicionados: {gids}")
        print(f"üìã Total de GIDs customizados: {len(self.gids_customizados)}")
    
    def definir_gids(self, gids_lista):
        """Define uma lista completa de GIDs para busca"""
        self.gids_customizados = list(gids_lista)
        print(f"‚úÖ GIDs definidos: {self.gids_customizados}")
    
    def limpar_gids(self):
        """Remove todos os GIDs customizados (volta ao padr√£o)"""
        self.gids_customizados = []
        print("‚úÖ GIDs customizados removidos - usando busca padr√£o")
        
    def analisar_planilha(self, url_planilha):
        """
        An√°lise completa da planilha NPS
        Retorna resumo estruturado em texto
        """
        try:
            print("üöÄ Iniciando an√°lise completa NPS...")
            print(f"üìç Loja: {self.nome_loja}")
            
            # ETAPA 1: Extra√ß√£o autom√°tica das abas
            print("\nüì• ETAPA 1: Extra√ß√£o das Abas")
            if not self._extrair_abas_automaticamente(url_planilha):
                return "‚ùå Falha na extra√ß√£o das abas"
            
            # ETAPA 2: Padroniza√ß√£o dos dados
            print("\nüîß ETAPA 2: Padroniza√ß√£o dos Dados")
            self._padronizar_todos_dados()
            
            # ETAPA 3: C√°lculo das m√©tricas NPS
            print("\nüìä ETAPA 3: C√°lculo das M√©tricas NPS")
            self._calcular_metricas_nps()
            
            # ETAPA 4: An√°lise IA dos insights
            print("\nü§ñ ETAPA 4: An√°lise IA dos Insights")
            insights_ia = self._gerar_insights_ia()
            
            # ETAPA 5: Gera√ß√£o do resumo final
            print("\nüìã ETAPA 5: Gera√ß√£o do Resumo")
            resumo = self._gerar_resumo_completo(insights_ia)
            
            print("‚úÖ An√°lise conclu√≠da com sucesso!")
            return resumo
            
        except Exception as e:
            return f"‚ùå Erro na an√°lise: {str(e)}"
    
    def _extrair_abas_automaticamente(self, url):
        """Sistema multi-estrat√©gia para descobrir abas de qualquer planilha"""
        try:
            sheet_id = self._extrair_sheet_id(url)
            if not sheet_id:
                print("‚ùå ID da planilha n√£o encontrado")
                return False
            
            print("üîç Iniciando descoberta multi-estrat√©gia de abas...")
            
            # === ESTRAT√âGIA 0: PLANILHA ABA √öNICA (sua planilha especial) ===
            print("üéØ ESTRAT√âGIA 0: Verificando se √© planilha de aba √∫nica...")
            if self._tentar_extracao_aba_unica(sheet_id, url):
                return True
            
            # === ESTRAT√âGIA 1: GIDs CUSTOMIZADOS (mais r√°pido) ===
            if self.gids_customizados:
                print(f"üéØ ESTRAT√âGIA 1: Usando GIDs customizados: {self.gids_customizados}")
                abas_encontradas = self._buscar_por_gids_especificos(sheet_id, self.gids_customizados)
                if len(abas_encontradas) >= 2:  # Se encontrou pelo menos 2 abas
                    self.dados_abas = abas_encontradas
                    return self._finalizar_extracao(abas_encontradas)
            
            # === ESTRAT√âGIA 1.5: BUSCA POR √çNDICE DAS ABAS ===
            print("üéØ ESTRAT√âGIA 1.5: Busca por √≠ndice das abas...")
            abas_por_indice = self._buscar_por_indice_abas(sheet_id)
            if len(abas_por_indice) >= 2:
                self.dados_abas = abas_por_indice
                return self._finalizar_extracao(abas_por_indice)
            
            # === ESTRAT√âGIA 1.7: BUSCA FOR√áADA POR NOMES EXATOS ===
            print("üéØ ESTRAT√âGIA 1.7: Busca for√ßada por nomes exatos das 3 abas...")
            abas_forcadas = self._buscar_forcado_nomes_exatos(sheet_id)
            if len(abas_forcadas) >= 2:
                self.dados_abas = abas_forcadas
                return self._finalizar_extracao(abas_forcadas)
            
            # === ESTRAT√âGIA 2: BUSCA DIRETA POR NOMES (SEM GIDs) ===
            print("üîç ESTRAT√âGIA 2: Busca direta por nomes de abas...")
            abas_diretas = self._buscar_abas_por_nomes_diretos(sheet_id)
            if len(abas_diretas) >= 2:
                self.dados_abas = abas_diretas
                return self._finalizar_extracao(abas_diretas)
            
            # === ESTRAT√âGIA 3: DESCOBERTA POR NOMES DAS ABAS ===
            print("üîç ESTRAT√âGIA 3: Tentando descobrir GIDs por nomes das abas...")
            abas_por_nomes = self._descobrir_gids_por_nomes(sheet_id)
            if len(abas_por_nomes) >= 2:
                self.dados_abas = abas_por_nomes
                return self._finalizar_extracao(abas_por_nomes)
            
            # === ESTRAT√âGIA 4: BUSCA INTELIGENTE OTIMIZADA ===
            print("üîç ESTRAT√âGIA 4: Busca inteligente com padr√µes otimizados...")
            abas_inteligente = self._busca_inteligente_otimizada(sheet_id, url)
            if len(abas_inteligente) >= 1:
                self.dados_abas = abas_inteligente
                return self._finalizar_extracao(abas_inteligente)
            
            # === ESTRAT√âGIA 5: BUSCA EXAUSTIVA (√∫ltimo recurso) ===
            print("üîç ESTRAT√âGIA 5: Busca exaustiva (√∫ltimo recurso)...")
            abas_exaustiva = self._busca_exaustiva(sheet_id)
            if len(abas_exaustiva) >= 1:
                self.dados_abas = abas_exaustiva
                return self._finalizar_extracao(abas_exaustiva)
            
            print("‚ùå Nenhuma aba v√°lida encontrada em todas as estrat√©gias")
            return False
                
        except Exception as e:
            print(f"‚ùå Erro na extra√ß√£o: {str(e)}")
            return False
    
    def _ler_csv_com_encoding(self, texto_csv):
        """L√™ CSV tentando m√∫ltiplos encodings"""
        encodings = ['utf-8', 'latin-1', 'cp1252']
        
        for encoding in encodings:
            try:
                # Trata bytes vs string
                if isinstance(texto_csv, bytes):
                    texto_decoded = texto_csv.decode(encoding)
                else:
                    texto_decoded = str(texto_csv)
                
                df = pd.read_csv(io.StringIO(texto_decoded))
                if len(df) > 0:  # Verifica se o DataFrame n√£o est√° vazio
                    return df
            except Exception:
                continue
        
        # Fallback para DataFrame vazio se tudo falhar
        print("   ‚ö†Ô∏è Erro ao ler CSV - retornando DataFrame vazio")
        return pd.DataFrame()
    
    def _identificar_tipo_aba(self, df):
        """Identifica o tipo da aba baseado na estrutura das colunas - Sistema Inteligente com Prioriza√ß√£o"""
        # Corrige encoding das colunas primeiro
        colunas_corrigidas = [self._corrigir_encoding_comum(str(col)) for col in df.columns]
        
        print(f"   üîç Analisando colunas: {colunas_corrigidas}")
        
        colunas_texto = ' '.join(colunas_corrigidas)
        
        # === PRIORIDADE 1: DETECTAR D+30 (WhatsApp √© indicador muito forte) ===
        palavras_whatsapp = ['whatsapp', 'zap', 'wpp', 'zapzap', 'whats', 'what', 'watts']
        tem_whatsapp = any(palavra in colunas_texto for palavra in palavras_whatsapp)
        
        # Se tem WhatsApp, √© MUITO provavelmente D+30, mesmo que tenha outras palavras
        if tem_whatsapp:
            whatsapp_encontrados = [p for p in palavras_whatsapp if p in colunas_texto]
            print(f"   ‚úÖ Detectado NPS D+30 (PRIORIDADE: WhatsApp): {whatsapp_encontrados}")
            return 'NPS_D30'
        
        # Outras palavras D+30 (sem WhatsApp)
        outras_palavras_d30 = [
            'produto', 'product', 'd+30', 'd30', 'nps d+30', 'nps d30',
            'trinta', '30', 'pos-venda', 'pos venda', 'satisfacao produto',
            'qualidade produto', 'mercadoria', 'oculos', '√≥culos'
        ]
        palavras_d30_encontradas = [p for p in outras_palavras_d30 if p in colunas_texto]
        if palavras_d30_encontradas:
            print(f"   ‚úÖ Detectado NPS D+30 (outras palavras): {palavras_d30_encontradas}")
            return 'NPS_D30'
        
        # === PRIORIDADE 2: DETECTAR D+1 (telefone sem WhatsApp) ===
        palavras_telefone = ['telefone', 'fone', 'phone', 'tel']
        tem_telefone = any(palavra in colunas_texto for palavra in palavras_telefone)
        
        if tem_telefone and not tem_whatsapp:
            print(f"   ‚úÖ Detectado NPS D+1 (telefone sem WhatsApp)")
            return 'NPS_D1'
        
        # === PRIORIDADE 3: NPS RUIM (casos cr√≠ticos com gest√£o) ===
        # Palavras espec√≠ficas de resolu√ß√£o/gest√£o de casos cr√≠ticos (MELHORADAS)
        palavras_gestao_casos = [
            'situacao', 'situa√ß√£o', 'situacao', 'situacaao',  # Varia√ß√µes de situa√ß√£o
            'resolucao', 'resolu√ß√£o', 'resolucao', 'resou√ß√£o', 'resoucao',  # Varia√ß√µes de resolu√ß√£o
            'comentario_da_resolucao', 'comentario_resolucao', 'comentario da resolucao',
            'fonte', 'origem', 'canal', 'motivo', 'problema',
            'data_resolucao', 'data_resolu√ß√£o', 'data resou√ß√£o', 'resolvido', 'pendente',
            'analise', 'an√°lise', 'tratamento', 'followup', 'follow_up',
            'ruim', 'critico', 'problemas', 'reclamacao', 'reclama√ß√£o', 'status'
        ]
        
        # Busca mais espec√≠fica para detectar situa√ß√£o/resolu√ß√£o com acentos
        tem_situacao_variantes = any(palavra in colunas_texto for palavra in [
            'situacao', 'situa√ß√£o', 'situacaao', 'situac√£o'
        ])
        tem_resolucao_variantes = any(palavra in colunas_texto for palavra in [
            'resolucao', 'resolu√ß√£o', 'resou√ß√£o', 'resoucao'
        ])
        tem_fonte = any(palavra in colunas_texto for palavra in ['fonte', 'origem'])
        tem_bot = any(palavra in colunas_texto for palavra in ['bot', 'id_bot', 'id bot'])
        
        palavras_gestao_encontradas = [p for p in palavras_gestao_casos if p in colunas_texto]
        
        # CRIT√âRIO MAIS ESPEC√çFICO para NPS_Ruim:
        # Se tem bot + (situa√ß√£o OU resolu√ß√£o OU fonte), √© NPS_Ruim
        if tem_bot and (tem_situacao_variantes or tem_resolucao_variantes or tem_fonte):
            indicadores = []
            if tem_situacao_variantes: indicadores.append('situacao')
            if tem_resolucao_variantes: indicadores.append('resolucao') 
            if tem_fonte: indicadores.append('fonte')
            indicadores.append('bot')
            print(f"   ‚úÖ Detectado NPS Ruim (gest√£o espec√≠fica): {indicadores}")
            return 'NPS_Ruim'
        
        # Fallback original: pelo menos 2 indicadores de gest√£o
        if len(palavras_gestao_encontradas) >= 2:
            print(f"   ‚úÖ Detectado NPS Ruim (m√∫ltiplos indicadores): {palavras_gestao_encontradas}")
            return 'NPS_Ruim'
        
        # === FALLBACK: Se tem bot mas n√£o outros indicadores, pode ser dados gerais ===
        if tem_bot:
            print(f"   ‚ö†Ô∏è Bot detectado mas sem indicadores de gest√£o - assumindo dados gerais")
            return 'Dados_Gerais'
        
        # === M√âTODO 2: SISTEMA DE PONTUA√á√ÉO AVAN√áADO ===
        
        # Se o m√©todo original n√£o funcionou, usa pontua√ß√£o avan√ßada
        palavras_avaliacao = ['avaliacao', 'avalia√ß√£o', 'nota', 'score', 'rating', 'avaliaacaao']
        if any(palavra in ' '.join(colunas_corrigidas) for palavra in palavras_avaliacao):
            print(f"   üîç M√©todo original n√£o identificou - usando an√°lise avan√ßada...")
            
            # An√°lise DETALHADA baseada no conte√∫do dos dados
            if len(df) > 0:
                # Analisa m√∫ltiplas linhas, n√£o s√≥ a primeira
                amostra_dados = df.head(10).astype(str).apply(lambda x: ' '.join(x), axis=1).str.lower()
                conteudo_completo = ' '.join(amostra_dados)
                
                print(f"   üîç Analisando conte√∫do: {conteudo_completo[:200]}...")
                
                # Sistema de pontua√ß√£o melhorado
                scores = {'NPS_Ruim': 0, 'NPS_D30': 0, 'NPS_D1': 0}
                
                # Padr√µes NPS Ruim no conte√∫do
                padroes_ruim = [
                    'ruim', 'critico', 'problema', 'reclamacao', 'insatisfeito',
                    'pendente', 'resolvido', 'em andamento', 'analise',
                    'fonte', 'canal', 'motivo', 'situacao', 'status'
                ]
                
                score_ruim = sum(1 for padrao in padroes_ruim if padrao in conteudo_completo)
                scores['NPS_Ruim'] = score_ruim
                
                # Padr√µes D+30 no conte√∫do (melhorado)
                padroes_d30 = [
                    'whats', 'zap', 'wpp', '55', '+55', 'produto', 'product',
                    'd+30', 'd30', 'trinta', 'pos-venda', 'satisfacao',
                    'qualidade', 'mercadoria', 'oculos', '√≥culos', 'lente',
                    'armacao', 'arma√ß√£o', 'grau', 'receita', 'laboratorio'
                ]
                score_d30 = sum(1 for padrao in padroes_d30 if padrao in conteudo_completo)
                scores['NPS_D30'] = score_d30
                
                # Padr√µes D+1 no conte√∫do  
                padroes_d1 = ['atendimento', 'servico', 'telefone']
                score_d1 = sum(1 for padrao in padroes_d1 if padrao in conteudo_completo)
                scores['NPS_D1'] = score_d1
                
                print(f"   üìä Scores de conte√∫do: NPS_Ruim({score_ruim}) | D30({score_d30}) | D1({score_d1})")
                
                # Decis√£o baseada em pontua√ß√£o
                if score_ruim >= 2:  # Se encontrar 2+ padr√µes de NPS Ruim
                    print(f"   ‚úÖ Identificado como NPS_Ruim (an√°lise de conte√∫do)")
                    return 'NPS_Ruim'
                elif score_d30 >= 1:  # Se encontrar WhatsApp
                    print(f"   ‚úÖ Identificado como NPS_D30 (an√°lise de conte√∫do)")
                    return 'NPS_D30'
                elif score_d1 >= 1 or tem_telefone:  # Se encontrar padr√µes D+1 ou tem telefone
                    print(f"   ‚úÖ Identificado como NPS_D1 (an√°lise de conte√∫do)")
                    return 'NPS_D1'
            
            # Fallback para D+1 se tem avalia√ß√£o (ORIGINAL)
            print(f"   ‚úÖ Fallback: NPS_D1 (tem avalia√ß√£o)")
            return 'NPS_D1'
        
        print(f"   ‚ö†Ô∏è Aba n√£o identificada (sem colunas de avalia√ß√£o)")
        return 'desconhecido'
    
    def _padronizar_todos_dados(self):
        """Padroniza dados de todas as abas"""
        for tipo_aba, df in self.dados_abas.items():
            try:
                # Padroniza nomes das colunas
                df_padronizado = self._padronizar_colunas(df)
                
                # Garante que Avalia√ß√£o seja num√©rica
                df_padronizado = self._padronizar_avaliacao(df_padronizado)
                
                # Remove linhas vazias
                df_padronizado = df_padronizado.dropna(how='all')
                
                self.dados_abas[tipo_aba] = df_padronizado
                print(f"‚úÖ {tipo_aba}: dados padronizados")
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erro na padroniza√ß√£o de {tipo_aba}: {str(e)}")
    
    def _padronizar_colunas(self, df):
        """Padroniza nomes das colunas: remove acentos, espa√ßos ‚Üí underscore"""
        df_novo = df.copy()
        
        colunas_padronizadas = {}
        for col in df.columns:
            # Remove acentos
            col_sem_acento = self._remover_acentos(str(col))
            # Min√∫sculo
            col_lower = col_sem_acento.lower()
            # Remove caracteres especiais e substitui espa√ßos
            col_limpo = re.sub(r'[^\w\s]', '', col_lower)
            col_final = re.sub(r'\s+', '_', col_limpo).strip('_')
            
            colunas_padronizadas[col] = col_final
        
        return df_novo.rename(columns=colunas_padronizadas)
    
    def _remover_acentos(self, texto):
        """Remove acentos de uma string"""
        # Primeiro corrige problemas comuns de encoding
        texto = self._corrigir_encoding_comum(texto)
        # Depois remove acentos normalmente
        return unicodedata.normalize('NFD', texto).encode('ascii', 'ignore').decode('ascii')
    
    def _corrigir_encoding_comum(self, texto):
        """Corrige problemas comuns de encoding"""
        corrections = {
            'avalia√£√£o': 'avaliacao',
            'avalia√ß√£o': 'avaliacao',
            'avaliaa¬ßa¬£o': 'avaliacao',  # Encoding espec√≠fico encontrado
            'coment√£rio': 'comentario', 
            'coment√°rio': 'comentario',
            'comenta¬°rio': 'comentario',  # Encoding espec√≠fico encontrado
            'situa√£√£o': 'situacao',
            'situa√ß√£o': 'situacao',
            'resolu√£√£o': 'resolucao',
            'resolu√ß√£o': 'resolucao',
            'telefon√É¬™': 'telefone',
            'whatsap√É¬™': 'whatsapp',
            '¬ß': 'c',  # Corrige caracteres espec√≠ficos
            '¬£': 'a',
            '¬°': 'a',
            '√£': 'a',
            '√ß': 'c',
            '√©': 'e',
            '√≠': 'i',
            '√≥': 'o',
            '√∫': 'u',
            '√¢': 'a',
            '√™': 'e',
            '√¥': 'o'
        }
        
        texto_corrigido = str(texto).lower()
        for erro, correto in corrections.items():
            texto_corrigido = texto_corrigido.replace(erro, correto)
        
        return texto_corrigido
    
    def _padronizar_avaliacao(self, df):
        """Garante que a coluna Avalia√ß√£o seja num√©rica"""
        # Lista expandida de poss√≠veis nomes para coluna de avalia√ß√£o
        nomes_avaliacao = [
            'avaliacao', 'avalia√ßao', 'avalia√£√£o', 'avalia√ß√£o', 'avaliaacaao',
            'nota', 'score', 'rating', 'pontuacao', 'pontua√ß√£o',
            'satisfaction', 'satisfacao', 'satisfa√ß√£o'
        ]
        
        col_avaliacao = self._encontrar_coluna_por_nomes(df.columns, nomes_avaliacao)
        
        if col_avaliacao:
            df[col_avaliacao] = pd.to_numeric(df[col_avaliacao], errors='coerce')
            print(f"   ‚úÖ Coluna de avalia√ß√£o encontrada: '{col_avaliacao}'")
        else:
            print("   ‚ö†Ô∏è Coluna de avalia√ß√£o n√£o encontrada")
        
        return df
    
    def _encontrar_coluna_por_nomes(self, colunas, nomes_possiveis):
        """Encontra uma coluna baseada em lista de nomes poss√≠veis"""
        for col in colunas:
            col_limpo = self._corrigir_encoding_comum(str(col))
            for nome in nomes_possiveis:
                if nome in col_limpo:
                    return col
        return None
    
    def _calcular_metricas_nps(self):
        """Calcula m√©tricas NPS para cada aba"""
        for tipo_aba, df in self.dados_abas.items():
            try:
                if tipo_aba in ['NPS_D1', 'NPS_D30']:
                    metricas = self._calcular_nps_aba(df, tipo_aba)
                    self.metricas_calculadas[tipo_aba] = metricas
                    print(f"‚úÖ {tipo_aba}: m√©tricas calculadas")
                elif tipo_aba == 'NPS_Ruim':
                    # Para NPS Ruim, fazemos an√°lise diferente
                    analise_ruim = self._analisar_nps_ruim(df)
                    self.metricas_calculadas[tipo_aba] = analise_ruim
                    print(f"‚úÖ {tipo_aba}: an√°lise de casos cr√≠ticos conclu√≠da")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Erro no c√°lculo de m√©tricas para {tipo_aba}: {str(e)}")
    
    def _calcular_nps_aba(self, df, tipo_aba):
        """Calcula NPS para uma aba espec√≠fica (D+1 ou D+30)"""
        # Encontra coluna de avalia√ß√£o usando m√©todo melhorado
        nomes_avaliacao = [
            'avaliacao', 'avalia√ßao', 'avalia√£√£o', 'avalia√ß√£o', 'avaliaacaao',
            'nota', 'score', 'rating', 'pontuacao', 'pontua√ß√£o'
        ]
        
        col_avaliacao = self._encontrar_coluna_por_nomes(df.columns, nomes_avaliacao)
        
        if not col_avaliacao:
            return {'erro': 'Coluna de avalia√ß√£o n√£o encontrada'}
        
        # Remove valores inv√°lidos e faz limpeza rigorosa
        avaliacoes_validas = df[col_avaliacao].dropna()
        
        # Remove valores n√£o num√©ricos ou fora do range esperado (0-10)
        avaliacoes_validas = avaliacoes_validas[
            (avaliacoes_validas >= 0) & (avaliacoes_validas <= 10)
        ]
        
        total_respostas = len(avaliacoes_validas)
        
        if total_respostas == 0:
            return {'erro': 'Nenhuma avalia√ß√£o v√°lida encontrada (range 0-10)'}
        
        # Classifica conforme crit√©rios NPS
        promotores = len(avaliacoes_validas[avaliacoes_validas >= 9])
        neutros = len(avaliacoes_validas[(avaliacoes_validas >= 7) & (avaliacoes_validas <= 8)])
        detratores = len(avaliacoes_validas[avaliacoes_validas <= 6])
        
        # Calcula percentuais
        perc_promotores = (promotores / total_respostas) * 100
        perc_neutros = (neutros / total_respostas) * 100
        perc_detratores = (detratores / total_respostas) * 100
        
        # Score NPS
        nps_score = perc_promotores - perc_detratores
        
        return {
            'tipo': 'Atendimento' if tipo_aba == 'NPS_D1' else 'Produto',
            'total_respostas': total_respostas,
            'promotores': {'count': promotores, 'percentual': perc_promotores},
            'neutros': {'count': neutros, 'percentual': perc_neutros},
            'detratores': {'count': detratores, 'percentual': perc_detratores},
            'nps_score': nps_score,
            'nota_media': avaliacoes_validas.mean()
        }
    
    def _analisar_nps_ruim(self, df):
        """Analisa casos cr√≠ticos da aba NPS Ruim"""
        try:
            # Encontra colunas importantes usando m√©todo melhorado
            nomes_avaliacao = ['avaliacao', 'avalia√ßao', 'avalia√£√£o', 'avaliaacaao', 'nota', 'score']
            nomes_comentario = ['comentario', 'coment√°rio', 'comment', 'feedback', 'observacao']
            nomes_vendedor = ['vendedor', 'atendente', 'consultor', 'funcionario', 'agent']
            nomes_loja = ['loja', 'store', 'filial', 'unidade']
            
            col_avaliacao = self._encontrar_coluna_por_nomes(df.columns, nomes_avaliacao)
            col_comentario = self._encontrar_coluna_por_nomes(df.columns, nomes_comentario)
            col_vendedor = self._encontrar_coluna_por_nomes(df.columns, nomes_vendedor)
            col_loja = self._encontrar_coluna_por_nomes(df.columns, nomes_loja)
            
            total_casos = len(df)
            
            # Casos mais cr√≠ticos (menores notas)
            casos_criticos = []
            if col_avaliacao:
                df_ordenado = df.sort_values(col_avaliacao, na_position='last')
                
                for i, (idx, row) in enumerate(df_ordenado.head(10).iterrows()):
                    caso = {
                        'posicao': i + 1,
                        'avaliacao': row[col_avaliacao] if col_avaliacao else 'N/A',
                        'comentario': str(row[col_comentario])[:200] if col_comentario and pd.notna(row[col_comentario]) else 'Sem coment√°rio',
                        'vendedor': row[col_vendedor] if col_vendedor and pd.notna(row[col_vendedor]) else 'N/A',
                        'loja': row[col_loja] if col_loja and pd.notna(row[col_loja]) else 'N/A'
                    }
                    casos_criticos.append(caso)
            
            return {
                'tipo': 'Casos Cr√≠ticos',
                'total_casos': total_casos,
                'casos_criticos': casos_criticos
            }
            
        except Exception as e:
            return {'erro': f'Erro na an√°lise de casos cr√≠ticos: {str(e)}'}
    
    def _gerar_resumo_completo(self, insights_ia):
        """Gera resumo final estruturado com insights IA"""
        try:
            resumo = f"""
üìÖ Data da An√°lise: {datetime.now().strftime('%d/%m/%Y √†s %H:%M')}

"""
            
            # Resumo das m√©tricas NPS D+1 e D+30
            resumo += self._gerar_secao_metricas_nps()
            
            # An√°lise de casos cr√≠ticos
            resumo += self._gerar_secao_casos_criticos()
            
            # INSIGHTS IA - Nova se√ß√£o
            resumo += self._gerar_secao_insights_ia(insights_ia)
            
            return resumo
            
        except Exception as e:
            return f"Erro na gera√ß√£o do resumo: {str(e)}"
    
    def _gerar_secao_insights_ia(self, insights_ia):
        """Gera se√ß√£o com insights da IA"""
        secao = """
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    INSIGHTS IA                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

"""
        secao += insights_ia + "\n\n"
        return secao
    
    def _gerar_secao_metricas_nps(self):
        """Gera se√ß√£o com m√©tricas NPS de D+1 e D+30"""
        secao = """
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     M√âTRICAS NPS                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

"""
        
        for tipo_aba in ['NPS_D1', 'NPS_D30']:
            if tipo_aba in self.metricas_calculadas:
                metricas = self.metricas_calculadas[tipo_aba]
                
                if 'erro' not in metricas:
                    tipo_nome = metricas['tipo']
                    secao += f"""
üéØ {tipo_nome.upper()}:
   üìä Total de Respostas: {metricas['total_respostas']:,}
   üìà Score NPS: {metricas['nps_score']:.1f}
   ‚≠ê Nota M√©dia: {metricas['nota_media']:.2f}
   
   üìã Distribui√ß√£o:
   üü¢ Promotores (9-10): {metricas['promotores']['count']:,} ({metricas['promotores']['percentual']:.1f}%)
   üü° Neutros (7-8):     {metricas['neutros']['count']:,} ({metricas['neutros']['percentual']:.1f}%)
   üî¥ Detratores (‚â§6):   {metricas['detratores']['count']:,} ({metricas['detratores']['percentual']:.1f}%)
"""
                else:
                    secao += f"\n‚ö†Ô∏è {tipo_aba}: {metricas['erro']}\n"
        
        return secao
    
    def _gerar_secao_casos_criticos(self):
        """Gera se√ß√£o com casos cr√≠ticos do NPS Ruim"""
        secao = """
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   CASOS CR√çTICOS                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

"""
        
        if 'NPS_Ruim' in self.metricas_calculadas:
            dados_ruim = self.metricas_calculadas['NPS_Ruim']
            
            if 'erro' not in dados_ruim:
                secao += f"üìä Total de Casos Cr√≠ticos: {dados_ruim['total_casos']:,}\n\n"
                secao += "üîç 10 CASOS MAIS CR√çTICOS (menores notas):\n\n"
                
                for caso in dados_ruim['casos_criticos']:
                    secao += f"""
{caso['posicao']:2d}. üìç Nota: {caso['avaliacao']} | Vendedor: {caso['vendedor']} | Loja: {caso['loja']}
    üí¨ "{caso['comentario']}"
"""
            else:
                secao += f"‚ö†Ô∏è NPS Ruim: {dados_ruim['erro']}\n"
        else:
            secao += "‚ö†Ô∏è Aba 'NPS Ruim' n√£o encontrada na planilha\n\n"
            secao += "üí° AN√ÅLISE ALTERNATIVA DE CASOS CR√çTICOS:\n"
            secao += self._analisar_detratores_das_abas_existentes()
        
        return secao
    
    def _gerar_secao_resumo_geral(self):
        """Gera se√ß√£o de resumo geral"""
        secao = """
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    RESUMO GERAL                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

"""
        
        total_respostas_geral = 0
        abas_processadas = 0
        
        for tipo_aba, metricas in self.metricas_calculadas.items():
            if 'erro' not in metricas:
                abas_processadas += 1
                if 'total_respostas' in metricas:
                    total_respostas_geral += metricas['total_respostas']
                elif 'total_casos' in metricas:
                    total_respostas_geral += metricas['total_casos']
        
        secao += f"""üìä ESTAT√çSTICAS GERAIS:
   ‚Ä¢ Abas processadas: {abas_processadas}/3
   ‚Ä¢ Total de registros analisados: {total_respostas_geral:,}
   ‚Ä¢ Planilha: Google Sheets (acesso p√∫blico)
   
üè™ Loja: {self.nome_loja}
‚è∞ Processado em: {datetime.now().strftime('%d/%m/%Y √†s %H:%M:%S')}
"""
        
        return secao
    
    def _analisar_detratores_das_abas_existentes(self):
        """Analisa detratores das abas D+1 e D+30 quando n√£o h√° aba NPS Ruim"""
        try:
            analise = ""
            
            for tipo_aba, df in self.dados_abas.items():
                if tipo_aba in ['NPS_D1', 'NPS_D30']:
                    # Encontra colunas importantes
                    nomes_avaliacao = ['avaliacao', 'avalia√ßao', 'avalia√£√£o', 'avaliaacaao', 'nota', 'score']
                    nomes_comentario = ['comentario', 'coment√°rio', 'comment', 'feedback', 'comentaario']
                    nomes_vendedor = ['vendedor', 'atendente', 'consultor', 'funcionario']
                    nomes_loja = ['loja', 'store', 'filial', 'unidade']
                    
                    col_avaliacao = self._encontrar_coluna_por_nomes(df.columns, nomes_avaliacao)
                    col_comentario = self._encontrar_coluna_por_nomes(df.columns, nomes_comentario)
                    col_vendedor = self._encontrar_coluna_por_nomes(df.columns, nomes_vendedor)
                    col_loja = self._encontrar_coluna_por_nomes(df.columns, nomes_loja)
                    
                    if col_avaliacao:
                        # Filtra detratores (nota ‚â§ 6)
                        detratores = df[df[col_avaliacao] <= 6]
                        
                        if len(detratores) > 0:
                            tipo_nome = 'D+1 (Atendimento)' if tipo_aba == 'NPS_D1' else 'D+30 (Produto)'
                            analise += f"\nüî¥ DETRATORES {tipo_nome}:\n"
                            analise += f"   üìä Total: {len(detratores)} casos\n\n"
                            
                            # Top 5 piores casos
                            detratores_ordenados = detratores.sort_values(col_avaliacao).head(5)
                            
                            for i, (idx, row) in enumerate(detratores_ordenados.iterrows(), 1):
                                nota = row[col_avaliacao] if pd.notna(row[col_avaliacao]) else 'N/A'
                                vendedor = row[col_vendedor] if col_vendedor and pd.notna(row[col_vendedor]) else 'N/A'
                                loja = row[col_loja] if col_loja and pd.notna(row[col_loja]) else 'N/A'
                                comentario = str(row[col_comentario])[:150] if col_comentario and pd.notna(row[col_comentario]) else 'Sem coment√°rio'
                                
                                analise += f"   {i}. üìç Nota: {nota} | {vendedor} | {loja}\n"
                                analise += f"      üí¨ \"{comentario}...\"\n\n"
            
            if not analise:
                analise = "   ‚úÖ Excelente! Poucos ou nenhum detrator encontrado nas abas dispon√≠veis.\n"
            
            return analise
            
        except Exception as e:
            return f"   ‚ùå Erro na an√°lise de detratores: {str(e)}\n"
    
    def _gerar_insights_ia(self):
        """Gera insights autom√°ticos usando IA"""
        try:
            print("ü§ñ Gerando insights com IA...")
            
            # Prepara dados resumidos para IA
            dados_para_ia = self._preparar_dados_para_ia()
            
            prompt = f"""
Analise os dados NPS da empresa {self.nome_loja} e gere insights estrat√©gicos:

DADOS RESUMIDOS:
{dados_para_ia}

GERE UM RELAT√ìRIO DE INSIGHTS NO FORMATO:

üéØ INSIGHTS PRINCIPAIS:
‚Ä¢ [Insight principal sobre performance]
‚Ä¢ [Insight sobre pontos fortes]
‚Ä¢ [Insight sobre oportunidades]

üìä AN√ÅLISE COMPARATIVA:
‚Ä¢ D+1 vs D+30: [Compara√ß√£o entre atendimento e produto]
‚Ä¢ Padr√µes identificados: [Padr√µes nos dados]

‚ö†Ô∏è PONTOS DE ATEN√á√ÉO:
‚Ä¢ [Principal problema identificado]
‚Ä¢ [Vendedores ou lojas que precisam aten√ß√£o]

üöÄ RECOMENDA√á√ïES ESTRAT√âGICAS:
1. [Recomenda√ß√£o urgente]
2. [Recomenda√ß√£o de melhoria]
3. [Recomenda√ß√£o preventiva]

Seja espec√≠fico, use dados reais e foque em a√ß√µes pr√°ticas.
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um consultor especialista em NPS e experi√™ncia do cliente. Seja preciso e actionable."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )
            
            insights = response.choices[0].message.content
            print("‚úÖ Insights IA gerados!")
            return insights
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro na gera√ß√£o de insights IA: {str(e)}")
            return self._gerar_insights_basicos()
    
    def _preparar_dados_para_ia(self):
        """Prepara resumo estruturado dos dados para IA"""
        try:
            resumo_ia = f"=== AN√ÅLISE NPS {self.nome_loja.upper()} ===\n\n"
            
            # M√©tricas de cada aba
            for tipo_aba, metricas in self.metricas_calculadas.items():
                if 'erro' not in metricas:
                    if tipo_aba in ['NPS_D1', 'NPS_D30']:
                        resumo_ia += f"üìä {metricas['tipo'].upper()}:\n"
                        resumo_ia += f"   ‚Ä¢ Total respostas: {metricas['total_respostas']:,}\n"
                        resumo_ia += f"   ‚Ä¢ Score NPS: {metricas['nps_score']:.1f}\n"
                        resumo_ia += f"   ‚Ä¢ Nota m√©dia: {metricas['nota_media']:.2f}\n"
                        resumo_ia += f"   ‚Ä¢ Promotores: {metricas['promotores']['count']} ({metricas['promotores']['percentual']:.1f}%)\n"
                        resumo_ia += f"   ‚Ä¢ Neutros: {metricas['neutros']['count']} ({metricas['neutros']['percentual']:.1f}%)\n"
                        resumo_ia += f"   ‚Ä¢ Detratores: {metricas['detratores']['count']} ({metricas['detratores']['percentual']:.1f}%)\n\n"
                    
                    elif tipo_aba == 'NPS_Ruim':
                        resumo_ia += f"üî¥ CASOS CR√çTICOS:\n"
                        resumo_ia += f"   ‚Ä¢ Total casos: {metricas['total_casos']}\n"
                        
                        # Amostra dos piores casos
                        if 'casos_criticos' in metricas and len(metricas['casos_criticos']) > 0:
                            resumo_ia += "   ‚Ä¢ Principais problemas:\n"
                            for caso in metricas['casos_criticos'][:3]:
                                resumo_ia += f"     - Nota {caso['avaliacao']} | {caso['vendedor']} | {caso['loja']}\n"
                        resumo_ia += "\n"
            
            # An√°lise de vendedores (se dispon√≠vel)
            resumo_ia += self._analisar_vendedores_para_ia()
            
            return resumo_ia
            
        except Exception as e:
            return f"Dados b√°sicos dispon√≠veis para {self.nome_loja}\nErro: {str(e)}"
    
    def _analisar_vendedores_para_ia(self):
        """Analisa performance dos vendedores para IA"""
        try:
            analise_vendedores = "\nüìà AN√ÅLISE DE VENDEDORES:\n"
            
            # Combina dados de todas as abas para an√°lise de vendedores
            todos_vendedores = {}
            
            for tipo_aba, df in self.dados_abas.items():
                col_vendedor = None
                col_avaliacao = None
                
                for col in df.columns:
                    col_lower = col.lower()
                    if 'vendedor' in col_lower:
                        col_vendedor = col
                    elif 'avaliacao' in col_lower or 'nota' in col_lower:
                        col_avaliacao = col
                
                if col_vendedor and col_avaliacao:
                    vendedores_aba = df.groupby(col_vendedor)[col_avaliacao].agg(['count', 'mean']).sort_values('mean', ascending=False)
                    
                    analise_vendedores += f"   ‚Ä¢ {tipo_aba}: {len(vendedores_aba)} vendedores √∫nicos\n"
                    if len(vendedores_aba) > 0:
                        melhor = vendedores_aba.index[0]
                        nota_melhor = vendedores_aba.iloc[0]['mean']
                        analise_vendedores += f"     Top: {melhor} (m√©dia {nota_melhor:.2f})\n"
            
            return analise_vendedores
            
        except Exception as e:
            return f"\n‚ö†Ô∏è Erro na an√°lise de vendedores: {str(e)}\n"
    
    def _gerar_insights_basicos(self):
        """Gera insights b√°sicos sem IA"""
        return """
üéØ INSIGHTS PRINCIPAIS:
‚Ä¢ Dados extra√≠dos e processados com sucesso
‚Ä¢ M√©tricas NPS calculadas conforme padr√£o de mercado
‚Ä¢ An√°lise segmentada por tipo de avalia√ß√£o

üìä AN√ÅLISE COMPARATIVA:
‚Ä¢ Sistema funcionando adequadamente
‚Ä¢ Dados estruturados para an√°lise

‚ö†Ô∏è PONTOS DE ATEN√á√ÉO:
‚Ä¢ Verificar conex√£o com IA para insights mais detalhados

üöÄ RECOMENDA√á√ïES ESTRAT√âGICAS:
1. Monitorar regularmente as m√©tricas NPS
2. Focar na melhoria cont√≠nua da experi√™ncia
3. Implementar a√ß√µes baseadas nos feedbacks
"""
    
    def _extrair_sheet_id(self, url):
        """Extrai ID da planilha da URL"""
        try:
            pattern = r'/spreadsheets/d/([a-zA-Z0-9-_]+)'
            match = re.search(pattern, url)
            return match.group(1) if match else None
        except:
            return None
    
    def _extrair_gid_da_url(self, url):
        """Extrai GID da URL (gid=n√∫mero)"""
        try:
            pattern = r'[?&#]gid=(\d+)'
            match = re.search(pattern, url)
            return int(match.group(1)) if match else None
        except:
            return None
    
    def _buscar_por_indice_abas(self, sheet_id):
        """ESTRAT√âGIA 1.5: Busca por √≠ndice das abas (0, 1, 4)"""
        abas_encontradas = {}
        
        # Mapeamento: aba 0 = NPS_Ruim, aba 1 = NPS_D1, aba 4 = NPS_D30
        indices_mapeamento = {
            0: 'NPS_Ruim',
            1: 'NPS_D1', 
            4: 'NPS_D30'
        }
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        print("   üîç Testando extra√ß√£o por √≠ndices de abas (0, 1, 4)...")
        
        for indice, tipo_esperado in indices_mapeamento.items():
            try:
                # URL para acessar aba por √≠ndice
                csv_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&single=true&gid={indice}"
                response = requests.get(csv_url, timeout=10, headers=headers)
                
                if (response.status_code == 200 and 
                    response.text.strip() and 
                    'Error' not in response.text and
                    len(response.text) > 50):
                    
                    df = self._ler_csv_com_encoding(response.text)
                    if len(df) > 1:
                        # Verifica o tipo real da aba
                        tipo_real = self._identificar_tipo_aba(df)
                        
                        # Usa o tipo identificado se for v√°lido, sen√£o usa o esperado
                        tipo_final = tipo_real if tipo_real != 'desconhecido' else tipo_esperado
                        
                        if tipo_final not in abas_encontradas:
                            abas_encontradas[tipo_final] = df
                            print(f"   ‚úÖ {tipo_final}: {len(df)} registros (√≠ndice {indice})")
                        
            except Exception as e:
                print(f"   ‚ö†Ô∏è Erro no √≠ndice {indice}: {str(e)[:50]}")
                continue
        
        return abas_encontradas
    
    def _buscar_forcado_nomes_exatos(self, sheet_id):
        """ESTRAT√âGIA 1.7: Busca for√ßada pelos nomes exatos das 3 abas NPS"""
        abas_encontradas = {}
        
        # Mapeamento FOR√áADO para garantir que as 3 abas sejam encontradas
        mapeamento_forcado = {
            'NPS D+1': 'NPS_D1',
            'NPS D+30': 'NPS_D30', 
            'NPS Ruim': 'NPS_Ruim'
        }
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        print(f"   üéØ For√ßando busca pelos nomes: {list(mapeamento_forcado.keys())}")
        
        for nome_aba, tipo_forcado in mapeamento_forcado.items():
            try:
                # Busca direta pelo nome exato
                nome_encoded = nome_aba.replace(' ', '%20').replace('+', '%2B')
                csv_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={nome_encoded}"
                
                response = requests.get(csv_url, timeout=10, headers=headers)
                
                if (response.status_code == 200 and 
                    response.text.strip() and 
                    'Error' not in response.text and
                    len(response.text) > 100):
                    
                    df = self._ler_csv_com_encoding(response.text)
                    if len(df) > 1:
                        # FOR√áA o tipo baseado no nome se for uma aba NPS espec√≠fica
                        if nome_aba == 'NPS Ruim':
                            # Para aba "NPS Ruim", for√ßa o tipo independente da detec√ß√£o
                            tipo_final = tipo_forcado
                            print(f"   üîí FOR√áADO: '{nome_aba}' ‚Üí {tipo_forcado} (ignorando detec√ß√£o autom√°tica)")
                        else:
                            # Para outras abas, usa detec√ß√£o autom√°tica se poss√≠vel
                            tipo_detectado = self._identificar_tipo_aba(df)
                            tipo_final = tipo_detectado if tipo_detectado != 'desconhecido' and tipo_detectado != 'Dados_Gerais' else tipo_forcado
                        
                        abas_encontradas[tipo_final] = df
                        print(f"   ‚úÖ {tipo_final}: {len(df)} registros (nome for√ßado: '{nome_aba}')")
                        
            except Exception as e:
                print(f"   ‚ö†Ô∏è Erro na busca for√ßada '{nome_aba}': {str(e)[:50]}")
                continue
        
        return abas_encontradas
    
    # === M√âTODOS DAS ESTRAT√âGIAS DE DESCOBERTA ===
    
    def _buscar_por_gids_especificos(self, sheet_id, gids_lista):
        """ESTRAT√âGIA 1: Busca por GIDs espec√≠ficos fornecidos"""
        abas_encontradas = {}
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        for gid in gids_lista:
            # Retry com 2 tentativas por GID
            for tentativa in range(2):
                try:
                    csv_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}"
                    response = requests.get(csv_url, timeout=15, headers=headers)
                    
                    # Valida√ß√£o melhor de response
                    if (response.status_code == 200 and 
                        response.text.strip() and 
                        'Error' not in response.text and 
                        'Sorry, unable to open the file at this time' not in response.text and
                        len(response.text) > 50):  # Verifica se n√£o √© resposta de erro do Google
                        
                        df = self._ler_csv_com_encoding(response.text)
                        if len(df) > 1:
                            tipo_aba = self._identificar_tipo_aba(df)
                            if tipo_aba != 'desconhecido':
                                abas_encontradas[tipo_aba] = df
                                print(f"   ‚úÖ {tipo_aba}: {len(df)} registros (GID {gid})")
                                break  # Sucesso, sai do loop de retry
                            
                except Exception as e:
                    if tentativa == 1:  # √öltima tentativa
                        print(f"   ‚ö†Ô∏è Erro ap√≥s 2 tentativas no GID {gid}: {str(e)[:50]}")
                    continue
        
        return abas_encontradas
    
    def _buscar_abas_por_nomes_diretos(self, sheet_id):
        """ESTRAT√âGIA 2: Busca direta por nomes de abas (SEM GIDs)"""
        abas_encontradas = {}
        
        # Lista expandida de poss√≠veis nomes para D+30
        nomes_d30 = [
            'NPS D+30', 'NPS D30', 'nps d+30', 'nps d30', 'D+30', 'D30', 'd+30', 'd30',
            'NPS D +30', 'NPS D +30', 'Produto', 'PRODUTO', 'produto', 
            'Satisfa√ß√£o Produto', 'Avalia√ß√£o Produto', 'P√≥s-venda',
            'WhatsApp', 'Zap', 'WPP', 'Contato WhatsApp',
            'Mercad√£o D+30', 'MDO D+30', '√ìculos D+30',
            'Trinta dias', '30 dias', 'Pos venda', 'Qualidade'
        ]
        
        # Lista expandida de poss√≠veis nomes para D+1  
        nomes_d1 = [
            'NPS D+1', 'NPS D1', 'nps d+1', 'nps d1', 'D+1', 'D1', 'd+1', 'd1',
            'NPS D +1', 'Atendimento', 'ATENDIMENTO', 'atendimento',
            'Telefone', 'Contato Telefone', 'Servico', 'Servi√ßo',
            'Mercad√£o D+1', 'MDO D+1', 'Um dia', '1 dia'
        ]
        
        # Lista expandida de poss√≠veis nomes para NPS Ruim
        nomes_ruim = [
            'NPS Ruim', 'NPS RUIM', 'nps ruim', 'Ruim', 'RUIM', 'ruim',
            'Cr√≠tico', 'CRITICO', 'critico', 'Casos Cr√≠ticos',
            'Problemas', 'Reclama√ß√µes', 'Detratores', 'Insatisfeitos',
            'Follow Up', 'Follow-up', 'Pendentes', 'Resolu√ß√£o'
        ]
        
        todos_nomes = {
            'NPS_D30': nomes_d30,
            'NPS_D1': nomes_d1, 
            'NPS_Ruim': nomes_ruim
        }
        
        for tipo_aba, lista_nomes in todos_nomes.items():
            for nome_aba in lista_nomes:
                try:
                    # Codifica o nome da aba para URL
                    nome_encoded = nome_aba.replace(' ', '%20').replace('+', '%2B')
                    csv_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={nome_encoded}"
                    
                    response = requests.get(csv_url, timeout=5)
                    
                    if response.status_code == 200 and response.text.strip() and 'Error' not in response.text:
                        df = self._ler_csv_com_encoding(response.text)
                        if len(df) > 1:  # Tem dados v√°lidos
                            # Confirma o tipo analisando o conte√∫do
                            tipo_confirmado = self._identificar_tipo_aba(df)
                            if tipo_confirmado != 'desconhecido':
                                abas_encontradas[tipo_confirmado] = df
                                print(f"   ‚úÖ {tipo_confirmado}: {len(df)} registros (nome: '{nome_aba}')")
                                break  # Encontrou esta aba, passa para pr√≥ximo tipo
                            elif tipo_aba not in abas_encontradas:  # Se n√£o confirmou tipo mas n√£o tem aba deste tipo ainda
                                abas_encontradas[tipo_aba] = df
                                print(f"   ‚úÖ {tipo_aba}: {len(df)} registros (nome: '{nome_aba}' - assumido)")
                                break
                                
                except Exception:
                    continue
        
        return abas_encontradas
    
    def _descobrir_gids_por_nomes(self, sheet_id):
        """ESTRAT√âGIA 2: Tenta descobrir GIDs pelos nomes das abas usando padr√µes HTML"""
        abas_encontradas = {}
        
        try:
            print("   üîç Analisando estrutura da planilha...")
            
            # Testa GIDs baseados em padr√µes de nomes conhecidos
            gids_por_nomes = self._gerar_gids_por_padroes_nomes()
            
            for gid in gids_por_nomes:
                try:
                    csv_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}"
                    response = requests.get(csv_url, timeout=5)
                    
                    if response.status_code == 200 and response.text.strip():
                        df = self._ler_csv_com_encoding(response.text)
                        if len(df) > 1:
                            tipo_aba = self._identificar_tipo_aba(df)
                            if tipo_aba != 'desconhecido' and tipo_aba not in abas_encontradas:
                                abas_encontradas[tipo_aba] = df
                                print(f"   ‚úÖ {tipo_aba}: {len(df)} registros (GID {gid} - por padr√£o)")
                                
                except Exception:
                    continue
                    
        except Exception as e:
            print(f"   ‚ö†Ô∏è Erro na descoberta por nomes: {str(e)}")
        
        return abas_encontradas
    
    def _busca_inteligente_otimizada(self, sheet_id, url):
        """ESTRAT√âGIA 3: Busca inteligente com padr√µes otimizados"""
        abas_encontradas = {}
        
        # GIDs inteligentes baseados na URL e padr√µes comuns
        gids_inteligentes = []
        
        # Extrai GID da URL e gera varia√ß√µes
        url_gid = self._extrair_gid_da_url(url)
        if url_gid:
            print(f"   üéØ GID da URL: {url_gid}")
            # Varia√ß√µes pr√≥ximas mais amplas
            for i in range(-10, 11):
                if i != 0:
                    gids_inteligentes.append(url_gid + i)
            
            # Padr√µes matem√°ticos comuns
            gids_inteligentes.extend([
                url_gid // 2, url_gid * 2,
                url_gid + 100, url_gid - 100,
                url_gid + 1000, url_gid - 1000
            ])
        
        # GIDs sequenciais comuns
        gids_inteligentes.extend(range(0, 30))  # 0-29
        gids_inteligentes.extend(range(100, 120))  # 100-119
        gids_inteligentes.extend(['od6', 'od7', 'od8', 'od9', 'od10'])
        
        # GIDs grandes comuns
        gids_comuns_grandes = [
            1410159651, 476804694, 1234567890, 987654321,
            1000000000, 1200000000, 1300000000, 1400000000
        ]
        gids_inteligentes.extend(gids_comuns_grandes)
        
        print(f"   üìä Testando {len(set(gids_inteligentes))} GIDs inteligentes...")
        
        for gid in set(gids_inteligentes):
            try:
                csv_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}"
                response = requests.get(csv_url, timeout=5)
                
                if response.status_code == 200 and response.text.strip():
                    df = self._ler_csv_com_encoding(response.text)
                    if len(df) > 1:
                        tipo_aba = self._identificar_tipo_aba(df)
                        if tipo_aba != 'desconhecido' and tipo_aba not in abas_encontradas:
                            abas_encontradas[tipo_aba] = df
                            print(f"   ‚úÖ {tipo_aba}: {len(df)} registros (GID {gid})")
                            
            except Exception:
                continue
        
        return abas_encontradas
    
    def _busca_exaustiva(self, sheet_id):
        """ESTRAT√âGIA 4: Busca exaustiva (√∫ltimo recurso)"""
        abas_encontradas = {}
        
        print("   ‚ö†Ô∏è Executando busca exaustiva - pode demorar...")
        
        # Sequ√™ncias num√©ricas extensas
        ranges_exaustivos = [
            range(0, 100),           # 0-99
            range(1000, 1100),       # 1000-1099
            range(10000, 10050),     # 10000-10049
            range(100000, 100050),   # 100000-100049
        ]
        
        # GIDs od (padr√£o Google)
        gids_od_extensivos = [f'od{i}' for i in range(6, 30)]
        
        todos_gids = []
        for r in ranges_exaustivos:
            todos_gids.extend(list(r))
        todos_gids.extend(gids_od_extensivos)
        
        print(f"   üìä Testando {len(todos_gids)} GIDs na busca exaustiva...")
        
        for i, gid in enumerate(todos_gids):
            # Mostra progresso a cada 50 GIDs
            if i % 50 == 0 and i > 0:
                print(f"   üìà Progresso: {i}/{len(todos_gids)} GIDs testados...")
            
            try:
                csv_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}"
                response = requests.get(csv_url, timeout=3)
                
                if response.status_code == 200 and response.text.strip():
                    df = self._ler_csv_com_encoding(response.text)
                    if len(df) > 1:
                        tipo_aba = self._identificar_tipo_aba(df)
                        if tipo_aba != 'desconhecido' and tipo_aba not in abas_encontradas:
                            abas_encontradas[tipo_aba] = df
                            print(f"   ‚úÖ {tipo_aba}: {len(df)} registros (GID {gid})")
                            
                            # Para se encontrou as 3 abas principais
                            if len(abas_encontradas) >= 3:
                                break
                            
            except Exception:
                continue
        
        return abas_encontradas
    
    def _gerar_gids_por_padroes_nomes(self):
        """Gera GIDs baseado em padr√µes comuns de nomenclatura"""
        gids_por_padroes = []
        
        # Padr√µes baseados em hash de nomes comuns (melhorado)
        nomes_comuns = [
            'd+1', 'd+30', 'ruim', 'nps d+1', 'nps d+30', 'nps ruim',
            'atendimento', 'produto', 'cr√≠tico', 'casos cr√≠ticos',
            'nps d30', 'nps d1', 'd30', 'd1', 'pos venda', 'pos-venda',
            'satisfacao produto', 'avaliacao produto', 'qualidade',
            'mercadao', 'mercad√£o', 'oculos', '√≥culos', 'whatsapp',
            'telefone', 'contato', 'follow up', 'feedback'
        ]
        
        # Simula GIDs que poderiam corresponder a esses nomes
        for i, nome in enumerate(nomes_comuns):
            # Gera alguns GIDs "plaus√≠veis" baseados no nome
            hash_base = hash(nome) % 1000000
            if hash_base < 0:
                hash_base = abs(hash_base)
            
            gids_por_padroes.extend([
                hash_base,
                hash_base + 1,
                hash_base + 10,
                hash_base + 100
            ])
        
        # Remove duplicatas e valores muito grandes
        gids_por_padroes = list(set([g for g in gids_por_padroes if 0 <= g <= 2000000000]))
        
        return gids_por_padroes[:100]  # Limita a 100 GIDs
    
    def _finalizar_extracao(self, abas_encontradas):
        """Finaliza o processo de extra√ß√£o com relat√≥rio e sistema de fallback inteligente"""
        print(f"üìä Total de abas encontradas: {len(abas_encontradas)}")
        
        for tipo, df in abas_encontradas.items():
            print(f"   üìã {tipo}: {len(df)} registros")
        
        # Informa quais abas foram encontradas e quais est√£o faltando
        abas_esperadas = ['NPS_D1', 'NPS_D30', 'NPS_Ruim']
        abas_encontradas_nomes = list(abas_encontradas.keys())
        abas_faltantes = [aba for aba in abas_esperadas if aba not in abas_encontradas_nomes]
        
        # === SISTEMA DE FALLBACK INTELIGENTE ===
        if abas_faltantes:
            print(f"‚ö†Ô∏è Abas n√£o encontradas: {', '.join(abas_faltantes)}")
            print("üîÑ Aplicando sistema de fallback inteligente...")
            
            # Tentar reclassificar abas mal identificadas
            abas_reclassificadas = self._aplicar_fallback_inteligente(abas_encontradas, abas_faltantes)
            
            if abas_reclassificadas:
                print("‚úÖ Fallback aplicado com sucesso!")
                # Atualiza as abas encontradas
                abas_encontradas.update(abas_reclassificadas)
                self.dados_abas.update(abas_reclassificadas)
                
                # Atualiza relat√≥rio
                print("üìä Abas ap√≥s fallback:")
                for tipo, df in abas_encontradas.items():
                    print(f"   üìã {tipo}: {len(df)} registros")
            else:
                print("   üí° Fallback n√£o encontrou abas adicionais")
        
        return True
    
    def _aplicar_fallback_inteligente(self, abas_encontradas, abas_faltantes):
        """Aplica sistema de fallback para reclassificar abas mal identificadas"""
        abas_reclassificadas = {}
        
        # Se faltou D+30, procura por abas com "Dados_Gerais" ou outras que tenham WhatsApp
        if 'NPS_D30' in abas_faltantes:
            for tipo_atual, df in list(abas_encontradas.items()):
                if tipo_atual in ['Dados_Gerais', 'NPS_Ruim']:  # Candidatos para reclassifica√ß√£o
                    colunas_texto = ' '.join([self._corrigir_encoding_comum(str(col)) for col in df.columns])
                    
                    # Se tem WhatsApp, √© muito provavelmente D+30
                    if any(palavra in colunas_texto for palavra in ['whatsapp', 'zap', 'wpp']):
                        print(f"   üîÑ Reclassificando {tipo_atual} como NPS_D30 (WhatsApp detectado)")
                        abas_reclassificadas['NPS_D30'] = df
                        # Remove da lista original para evitar duplica√ß√£o
                        if tipo_atual in abas_encontradas:
                            del abas_encontradas[tipo_atual]
                        break
        
        # Se faltou D+1, procura por abas com telefone
        if 'NPS_D1' in abas_faltantes:
            for tipo_atual, df in list(abas_encontradas.items()):
                if tipo_atual == 'Dados_Gerais':
                    colunas_texto = ' '.join([self._corrigir_encoding_comum(str(col)) for col in df.columns])
                    
                    # Se tem telefone mas n√£o WhatsApp
                    tem_telefone = any(palavra in colunas_texto for palavra in ['telefone', 'fone', 'phone'])
                    tem_whatsapp = any(palavra in colunas_texto for palavra in ['whatsapp', 'zap', 'wpp'])
                    
                    if tem_telefone and not tem_whatsapp:
                        print(f"   üîÑ Reclassificando {tipo_atual} como NPS_D1 (telefone sem WhatsApp)")
                        abas_reclassificadas['NPS_D1'] = df
                        if tipo_atual in abas_encontradas:
                            del abas_encontradas[tipo_atual]
                        break
        
        return abas_reclassificadas
    
    def _gerar_gids_comuns(self):
        """Gera lista de GIDs comuns baseado em padr√µes do Google Sheets"""
        gids_comuns = []
        
        # Padr√µes baseados em timestamps e sequ√™ncias comuns
        import time
        timestamp_atual = int(time.time())
        
        # GIDs baseados em anos recentes (2020-2025)
        for ano in range(2020, 2026):
            # Padr√µes t√≠picos do Google Sheets para cada ano
            base_ano = ano * 1000000
            gids_comuns.extend([
                base_ano, base_ano + 1, base_ano + 2, base_ano + 10, base_ano + 100
            ])
        
        # Sequ√™ncias num√©ricas comuns no Google Sheets
        sequencias_comuns = [
            # Sequ√™ncias pequenas
            list(range(100, 200)),
            list(range(500, 600)), 
            list(range(1000, 1100)),
            # Sequ√™ncias m√©dias  
            list(range(10000, 10100)),
            list(range(50000, 50100)),
            list(range(100000, 100100)),
            # GIDs espec√≠ficos comuns
            [476804694, 1410159651, 1202595829, 1234567890, 987654321],
            # Varia√ß√µes de milh√µes
            [1000000 + i for i in range(0, 50)],
            [10000000 + i for i in range(0, 50)],
            [100000000 + i for i in range(0, 50)]
        ]
        
        # Flattening das sequ√™ncias
        for seq in sequencias_comuns:
            gids_comuns.extend(seq)
        
        return gids_comuns
    
    def _tentar_extracao_aba_unica(self, sheet_id, url):
        """ESTRAT√âGIA ESPECIAL: Detecta planilhas de aba √∫nica com m√∫ltiplas fontes"""
        try:
            # Importa o extrator especial
            import os
            import sys
            import importlib.util
            
            # Carrega o m√≥dulo do extrator especial
            caminho_extrator = os.path.join(os.path.dirname(__file__), 'extrator_aba_unica_especial.py')
            if not os.path.exists(caminho_extrator):
                print("   ‚ùå Extrator especial n√£o encontrado")
                return False
            
            spec = importlib.util.spec_from_file_location("extrator_especial", caminho_extrator)
            extrator_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(extrator_module)
            
            # Usa o extrator especial
            extractor_especial = extrator_module.ExtratorAbaUnicaEspecial()
            resultado = extractor_especial.extrair_especial(url)
            
            if resultado.get('sucesso'):
                print("   ‚úÖ Detectada planilha tipo aba √∫nica!")
                
                # Converte para formato do sistema principal
                import pandas as pd
                self.dados_abas = {}
                
                for tipo, linhas in resultado['dados_separados'].items():
                    # Cria DataFrame
                    df = pd.DataFrame(linhas, columns=resultado['header'])
                    
                    # Mapeia tipos para formato do sistema
                    if tipo == 'D+30':
                        self.dados_abas['NPS_D30'] = df
                        print(f"   üìä NPS D+30: {len(df)} registros")
                    elif tipo == 'D+1':
                        self.dados_abas['NPS_D1'] = df
                        print(f"   üìä NPS D+1: {len(df)} registros")
                    elif tipo == 'NPS_Ruim':
                        self.dados_abas['NPS_Ruim'] = df
                        print(f"   üìä NPS Ruim: {len(df)} registros")
                
                # Implementa NPS Ruim automaticamente
                try:
                    print("   üîç Implementando NPS Ruim automaticamente...")
                    caminho_implementador = os.path.join(os.path.dirname(__file__), 'implementar_nps_ruim_completo.py')
                    if os.path.exists(caminho_implementador):
                        spec_ruim = importlib.util.spec_from_file_location("implementador_ruim", caminho_implementador)
                        implementador_module = importlib.util.module_from_spec(spec_ruim)
                        spec_ruim.loader.exec_module(implementador_module)
                        
                        implementador = implementador_module.ImplementadorNPSRuim()
                        resultado_ruim = implementador.implementar_nps_ruim_completo(url)
                        
                        if resultado_ruim.get('sucesso'):
                            # Carrega dados NPS Ruim
                            import csv
                            with open('extracao_especial_NPS_Ruim.csv', 'r', encoding='utf-8') as f:
                                reader = csv.DictReader(f)
                                dados_ruim = list(reader)
                            
                            # Converte para DataFrame
                            df_ruim = pd.DataFrame(dados_ruim)
                            self.dados_abas['NPS_Ruim'] = df_ruim
                            print(f"   ‚úÖ NPS Ruim implementado: {len(df_ruim)} casos")
                        
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Erro ao implementar NPS Ruim: {e}")
                
                return True
            
            return False
            
        except Exception as e:
            print(f"   ‚ùå Erro na estrat√©gia aba √∫nica: {e}")
            return False


def main():
    """Fun√ß√£o principal para uso direto"""
    print("üéØ ANALISADOR NPS COMPLETO")
    print("="*50)
    print("Cole o link da planilha Google Sheets para an√°lise autom√°tica")
    print()
    
    # Exemplo de uso:
    # analisador = AnalisadorNPSCompleto("Mercad√£o dos √ìculos")
    # resultado = analisador.analisar_planilha("URL_DA_PLANILHA")
    # print(resultado)


if __name__ == "__main__":
    main()